{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c912687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelFactoredEnv():\n",
    "    def __init__(self, k, d, num_trials, sigma=0.01, min_expected=0.3, max_expected=1, seed=0):\n",
    "        self.d = d\n",
    "        self.num_trials = num_trials\n",
    "        self.sigma=sigma\n",
    "        self.d_vect = np.linspace(0, d-1, d, dtype=int)\n",
    "        self.seed = seed\n",
    "        np.random.seed(self.seed)\n",
    "        self.avg_reward = np.random.uniform(min_expected, max_expected, (self.num_trials, self.d, k))\n",
    "    \n",
    "    def step(self, trial, action):\n",
    "        return self.avg_reward[trial, self.d_vect, action] + np.random.normal(0, self.sigma, self.d)\n",
    "\n",
    "    def get_expected(self, trial):\n",
    "        return self.avg_reward[trial, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2522ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactoredUCBAgent():\n",
    "    \"\"\"\n",
    "    This class implements the FRB algorithm in its anytime version\n",
    "    \"\"\"\n",
    "    def __init__(self, n_arms_vect, dim, sigma, max_reward=1, exploration_alpha=4):\n",
    "        self.n_arms_vect = n_arms_vect\n",
    "        self.dim = dim\n",
    "        assert self.dim == self.n_arms_vect.shape[0]\n",
    "        self.max_reward = max_reward\n",
    "        self.sigma = sigma\n",
    "        self.exploration_alpha = exploration_alpha\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.t = 1\n",
    "        self.last_pull = None\n",
    "        self.avg_reward = []\n",
    "        self.n_pulls = []\n",
    "        for size in self.n_arms_vect:\n",
    "            self.avg_reward.append(np.zeros(size))\n",
    "            self.n_pulls.append(np.zeros(size, dtype=int))\n",
    "        return self\n",
    "\n",
    "    def pull_arm(self):\n",
    "        self.last_pull = -1 * np.ones(self.dim, dtype=int)\n",
    "        for i in range(self.dim):\n",
    "            ucb1 = [self.avg_reward[i][a] + self.max_reward * self.sigma * np.sqrt(\n",
    "                self.exploration_alpha * np.log(self.t) / self.n_pulls[i][a]) for a in range(self.n_arms_vect[i])]\n",
    "            self.last_pull[i] = int(np.argmax(ucb1))\n",
    "            self.n_pulls[i][self.last_pull[i]] = self.n_pulls[i][self.last_pull[i]] + 1\n",
    "        return self.last_pull\n",
    "\n",
    "    def update(self, observations):\n",
    "        self.t += 1\n",
    "        for i in range(self.dim):\n",
    "            self.avg_reward[i][self.last_pull[i]] = (\n",
    "                self.avg_reward[i][self.last_pull[i]] *\n",
    "                (self.n_pulls[i][self.last_pull[i]] - 1) + observations[i]\n",
    "            ) / (self.n_pulls[i][self.last_pull[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3512e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FtrackAgent():\n",
    "    \"\"\"\n",
    "    This class implements F-track\n",
    "    \"\"\"\n",
    "    def __init__(self, k, d, sigma, T, c):\n",
    "        self.k = k\n",
    "        self.d = d\n",
    "        self.sigma = sigma\n",
    "        self.T = T\n",
    "        self.c = c\n",
    "        self.N0 = 10 * np.ceil(np.sqrt(np.log(T)))\n",
    "        self.eps = np.sqrt(2 * (sigma ** 2) * self._ft(1/np.log(T), c) / self.N0)\n",
    "        self.schedule = False\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.t = 0\n",
    "        self.last_pull = None\n",
    "        self.avg_reward = np.zeros((self.d, self.k))\n",
    "        self.n_pulls = np.zeros((self.d, self.k))\n",
    "        for size in self.n_arms_vect:\n",
    "            self.avg_reward.append(np.zeros(size))\n",
    "            self.n_pulls.append(np.zeros(size, dtype=int))\n",
    "        return self\n",
    "\n",
    "    def pull_arm(self):\n",
    "        if(self.t < self.N0*self.k): \n",
    "            self.last_pull = (self.t % self.k) * np.ones(self.d, dtype=int)\n",
    "        else: \n",
    "            if self.schedule == False:\n",
    "                self._create_schedule()\n",
    "            finished = self.action_vects_num == self.action_vects_num_pulled\n",
    "            self.action_vects_num[finished] = np.inf\n",
    "            to_pull = np.argmin(self.action_vects_num)\n",
    "            self.last_pull = self.action_vects[to_pull]\n",
    "            self.action_vects_num_pulled[to_pull] = self.action_vects_num_pulled[to_pull] + 1\n",
    "        return self.last_pull\n",
    "\n",
    "    def update(self, observations):\n",
    "        self.t += 1\n",
    "        for i in range(self.d):\n",
    "            self.avg_reward[i, self.last_pull[i]] = (\n",
    "                self.avg_reward[i, self.last_pull[i]] *\n",
    "                (self.n_pulls[i, self.last_pull[i]] - 1) + observations[i]\n",
    "            ) / (self.n_pulls[i, self.last_pull[i]])\n",
    "    \n",
    "    def _ft(self, delta, c):\n",
    "        return (1 + 1 / np.log(self.T)) * (c * np.log(np.log(self.T)) + np.log(1/delta))\n",
    "    \n",
    "    def _create_schedule():\n",
    "        self.avg_rewards_warmup = np.copy(self.avg_reward)\n",
    "        max_val = np.max(self.avg_rewards_warmup, axis=1)\n",
    "        max_idx = np.argmax(self.avg_rewards_warmup, axis=1)\n",
    "        deltas = max_val - self.avg_rewards_warmup\n",
    "        self.pulls_todo = np.zeros((self.d, self.T - self.N0*self.k))\n",
    "        ft = self._ft(1/self.T, self.c)\n",
    "        for i in range(self.d):\n",
    "            self.pulls_todo[i, :] = max_idx[i]\n",
    "            N = 2 * (self.sigma ** 2) * ft / (deltas[i, :] ** 2)\n",
    "            order = np.argsort(N)\n",
    "            N_ordered = N[order]\n",
    "            counter = 0\n",
    "            for j in range(self.k-1):\n",
    "                self.pulls_todo[i, counter:counter + N_ordered[j]] = order[j]\n",
    "                counter+=N_ordered[j]\n",
    "        self.action_vects = []\n",
    "        self.action_vects_num = []\n",
    "        for i in range(self.T - self.N0*self.k):\n",
    "            if (i == 0):\n",
    "                self.action_vects.append(self.pulls_todo[:, 0])\n",
    "                self.action_vects_num.append(1)\n",
    "            if self.pulls_todo[:, i] == self.action_vects[-1]:\n",
    "                self.action_vects_num[-1] = self.action_vects_num[-1] + 1\n",
    "            else:\n",
    "                self.action_vects.append(self.pulls_todo[:, i])\n",
    "                self.action_vects_num.append(1)\n",
    "        self.action_vects_num_pulled = list(np.zeros(len(self.action_vects_num)))     \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
