{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52278476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tikzplotlib as tkz\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os, sys\n",
    "\n",
    "_, filename = os.path.split(os.getcwd())\n",
    "if filename == 'notebooks':\n",
    "    old_dir = os.getcwd()\n",
    "    os.chdir('../')\n",
    "    print('Moving Current Directory from ' + old_dir + ' to ' + os.getcwd())\n",
    "else:\n",
    "    print('Current Directory is ' + os.getcwd())\n",
    "\n",
    "sys.path.append('./')  \n",
    "\n",
    "from FRB.agents import UCB1Agent, FactoredUCBAgent, TEA #, FactoredUCBAgentMM\n",
    "from FRB.env import FactoredEnv\n",
    "from FRB.utils import get_pulled_expected, compute_max_expected, create_action_matrix, get_sigma_square_eq_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactoredUCBAgentMM():\n",
    "    \"\"\"\n",
    "    This class implements the FRB MM optimal algorithm in its anytime\n",
    "    version for bounded variables\n",
    "    \"\"\"\n",
    "    def __init__(self, k, d, time_horizon, sigma=0.5,\n",
    "                 max_reward=1, exploration_alpha=4, bounded=True):\n",
    "        self.k = k\n",
    "        self.d = d\n",
    "        self.T = time_horizon\n",
    "        self.max_reward = max_reward\n",
    "        if bounded:\n",
    "            self.sigma = sigma\n",
    "        else:\n",
    "            self.sigma2 = (1 + sigma**2)**d\n",
    "            self.sigma = np.sqrt(self.sigma2)\n",
    "        self.exploration_alpha = exploration_alpha\n",
    "        self.num_actions = self.k ** self.d\n",
    "        self.bounded = bounded\n",
    "        # Creation of the action matrix\n",
    "        self.action_matrix = np.zeros(\n",
    "            (self.num_actions, self.d), dtype=int\n",
    "        )\n",
    "        for i in range(self.d):\n",
    "            vect = -1 * np.ones(self.k**(i+1))\n",
    "            external_repeats = int(self.k**(self.d-(i+1)))\n",
    "            internal_repeats = self.k**i\n",
    "            for j in range(self.k):\n",
    "                vect[j*internal_repeats:(j+1)*internal_repeats] = j\n",
    "            vect_new = np.copy(vect).reshape(-1, 1)\n",
    "            for _ in range(external_repeats-1):\n",
    "                vect_new = np.vstack((vect_new, vect.reshape(-1, 1)))\n",
    "            self.action_matrix[:, i] = vect_new.ravel()\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.t = 1\n",
    "        self.last_pull = None\n",
    "        self.n_min_pull = np.zeros(self.num_actions, dtype=int)\n",
    "        self.n_pulls = np.zeros((self.d, self.k), dtype=int)\n",
    "        self.observations = -1 * np.ones((self.d, self.k, self.T), dtype=int)\n",
    "        self.virtual_pulls_sum = np.zeros(self.num_actions)\n",
    "\n",
    "    def pull_arm(self):\n",
    "        # if self.bounded:\n",
    "        #     for i in range(self.num_actions):\n",
    "        #         action_vector = self.action_matrix[i, :]\n",
    "        #         new_min_pull = self.n_pulls[0, action_vector[0]]\n",
    "        #         for j in range(1, self.d):\n",
    "        #             new_min_pull = min(new_min_pull, self.n_pulls[j, action_vector[j]])\n",
    "        #         if new_min_pull != self.n_min_pull[i]:\n",
    "        #             self.n_min_pull[i] = new_min_pull\n",
    "        #             aux = 1\n",
    "        #             for j in range(self.d):\n",
    "        #                 aux *= self.observations[j, self.last_pull[j], self.n_min_pull[i]-1]\n",
    "        #             self.virtual_pulls_sum[i] += aux\n",
    "        #     mean = self.virtual_pulls_sum / self.n_min_pull\n",
    "        #     ucb = mean + self.sigma * np.sqrt(self.exploration_alpha * math.log(self.t) / self.n_min_pull)\n",
    "\n",
    "        # else:\n",
    "        #     for i in range(self.num_actions):\n",
    "        #         action_vector = self.action_matrix[i, :]\n",
    "        #         new_min_pull = self.n_pulls[0, action_vector[0]]\n",
    "        #         for j in range(1, self.d):\n",
    "        #             new_min_pull = min(new_min_pull, self.n_pulls[j, action_vector[j]])\n",
    "        #         if new_min_pull != self.n_min_pull[i]:\n",
    "        #             self.n_min_pull[i] = new_min_pull\n",
    "\n",
    "        #             if self.last_pull is not None and (action_vector == self.last_pull).any() and self.n_min_pull[i]>0:\n",
    "        #                 _observations = np.zeros((self.d, self.n_min_pull[i]-1))\n",
    "        #                 for h in range(self.d):\n",
    "        #                     _observations[h, :] = self.observations[h,action_vector[h],:self.n_min_pull[i]-1]\n",
    "        #                 x = np.prod(_observations, axis = 0)\n",
    "        #                 # self.virtual_pulls_sum[i] = self.trimmed_mean(x, self.sigma, 1/self.T, 1)\n",
    "        #                 self.virtual_pulls_sum[i] = np.mean(np.where(np.abs(x)<= self.threshold_lookup(self.t, 1),\n",
    "        #                                           x, 0))\n",
    "                    \n",
    "        #     mean = self.virtual_pulls_sum\n",
    "        #     ucb = mean + self.sigma * np.sqrt(4*self.exploration_alpha * math.log(self.t**2) / self.n_min_pull)\n",
    "\n",
    "        if self.bounded:\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(self.num_actions):\n",
    "                action_vector = self.action_matrix[i, :]\n",
    "                # Check if any element of action_vector has been pulled\n",
    "                if self.last_pull is not None and (action_vector == self.last_pull).any():\n",
    "                    # Check if the equivalent number of pulls of action_vector changes\n",
    "                    new_min_pull = self.n_pulls[0, action_vector[0]]\n",
    "                    for j in range(1, self.d):\n",
    "                        new_min_pull = min(new_min_pull, self.n_pulls[j, action_vector[j]])\n",
    "                    \n",
    "                    if new_min_pull > self.n_min_pull[i]:\n",
    "                        self.n_min_pull[i] = new_min_pull\n",
    "            for i in range(self.num_actions):\n",
    "                # Update estimated mean\n",
    "                _observations = np.zeros((self.d, self.n_min_pull[i]))\n",
    "            \n",
    "                for h in range(self.d):\n",
    "                    _observations[h, :] = self.observations[h,action_vector[h],:self.n_min_pull[i]]\n",
    "                \n",
    "                x = np.prod(_observations, axis = 0)\n",
    "                # self.virtual_pulls_sum[i] = self.trimmed_mean(x, self.sigma, 1/self.T, 1)\n",
    "                self.virtual_pulls_sum[i] = np.mean(np.where(np.abs(x) <= self.threshold_lookup(self.t, 1), x, 0))\n",
    "                \n",
    "            mean = self.virtual_pulls_sum\n",
    "            # ucb = mean + self.sigma * np.sqrt(2 * self.exploration_alpha * math.log(self.t) / self.n_min_pull)\n",
    "\n",
    "            ucb = mean + 4*self.sigma2**(1/2) * (2*np.log(self.t)/self.n_min_pull)**(1/2)\n",
    "\n",
    "\n",
    "            \n",
    "        self.last_pull = self.action_matrix[int(np.argmax(ucb)), :]\n",
    "        return self.last_pull\n",
    "\n",
    "    def update(self, observations):\n",
    "        self.t += 1\n",
    "        for i in range(self.d):\n",
    "            self.observations[i, self.last_pull[i], self.n_pulls[i, self.last_pull[i]]] = observations[i]\n",
    "            self.n_pulls[i, self.last_pull[i]] = self.n_pulls[i, self.last_pull[i]] + 1\n",
    "\n",
    "    def threshold_lookup(self, n, epsilon):\n",
    "        return (self.sigma2*n/np.log(n**-2))**(1/(1+epsilon))\n",
    "    \n",
    "    def trimmed_mean(self, x, u, delta, epsilon):\n",
    "        n = x.shape[0]\n",
    "        mask = np.zeros(x.shape)\n",
    "        _log = np.log(1/delta)\n",
    "        \n",
    "        t = np.arange(n)\n",
    "        mask = np.abs(x) <= (u*t - _log)**(1/(1+epsilon))\n",
    "        \n",
    "        mask = np.array(mask, dtype='bool')\n",
    "\n",
    "        mu = np.sum(x[mask]) / n\n",
    "        return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMRobustUCBAgent:\n",
    "    \n",
    "    def __init__(self, n_arms, u, *args, **kwargs):\n",
    "        self.n_arms = n_arms\n",
    "        self.u = u\n",
    "        # self.v = 2 * np.sqrt(self.u)\n",
    "        self.v = np.sqrt(self.u)\n",
    "        self.e_sqrt_16 = np.exp(1/16)\n",
    "        self.reset()\n",
    "        \n",
    "    def pull_arm(self): \n",
    "        # Truncated Mean\n",
    "        # ucbs = self.estimators + self.v * np.sqrt(np.sqrt(2)*2*np.log(self.t)/self.n_pulls)\n",
    "        # Median of Means\n",
    "        ucbs = self.estimators + np.sqrt(12 * self.v * 32 * np.log(self.e_sqrt_16 * self.t) / self.n_pulls)\n",
    "        ucbs = np.nan_to_num(ucbs, nan=np.inf)\n",
    "        self.last_pull = np.random.choice(np.where(ucbs == ucbs.max())[0])\n",
    "        self.n_pulls[self.last_pull] += 1\n",
    "        self.t += 1\n",
    "        return self.last_pull\n",
    "    \n",
    "    def update(self, X):\n",
    "        self.rewards[self.last_pull] = np.append(self.rewards[self.last_pull], X)\n",
    "        # Truncated Mean\n",
    "        # for a in range(self.n_arms):\n",
    "        #     self.estimators[a] = np.mean(np.where(np.abs(self.rewards[a]\n",
    "        #         ) <= self.threshold_lookup(self.t), self.rewards[a], 0))\n",
    "        # Median of Means\n",
    "        self.c = 2+32*np.log(self.t)\n",
    "        for a in range(self.n_arms):\n",
    "            k = max(int(min(self.c, self.n_pulls[a])/2), 1)\n",
    "            N = int(self.n_pulls[a]/k)\n",
    "            self.estimators[a] = np.median([np.mean(chunk) for chunk in np.array_split(self.rewards[a][:N*k], k)])\n",
    "\n",
    "    \n",
    "    def threshold_lookup(self, n):\n",
    "        return np.sqrt(self.u * n / (-2 * np.log(self.t)))\n",
    "    \n",
    "    def reset(self):\n",
    "        self.t = 1\n",
    "        self.last_pull = None\n",
    "        self.rewards = [np.array([]) for i in range(self.n_arms)]\n",
    "        self.estimators = np.ones(self.n_arms)*np.inf\n",
    "        self.n_pulls = np.zeros(self.n_arms, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewFactoredUCBAgentMM():\n",
    "    \"\"\"\n",
    "    This class implements the FRB MM optimal algorithm in its anytime\n",
    "    version for bounded variables\n",
    "    \"\"\"\n",
    "    def __init__(self, k, d, T, bounded, sigma):\n",
    "        self.k = k\n",
    "        self.d = d\n",
    "        self.T = T\n",
    "        if bounded:\n",
    "            self.v = sigma\n",
    "        else:\n",
    "            self.u = (1 + sigma**2)**d - 1\n",
    "            # self.v = 2 * np.sqrt(self.u)\n",
    "            self.v = np.sqrt(self.u)\n",
    "        self.num_actions = self.k ** self.d\n",
    "        self.bounded = bounded\n",
    "        # Creation of the action matrix\n",
    "        self.action_matrix = np.zeros(\n",
    "            (self.num_actions, self.d), dtype=int\n",
    "        )\n",
    "        for i in range(self.d):\n",
    "            vect = -1 * np.ones(self.k**(i+1))\n",
    "            external_repeats = int(self.k**(self.d-(i+1)))\n",
    "            internal_repeats = self.k**i\n",
    "            for j in range(self.k):\n",
    "                vect[j*internal_repeats:(j+1)*internal_repeats] = j\n",
    "            vect_new = np.copy(vect).reshape(-1, 1)\n",
    "            for _ in range(external_repeats-1):\n",
    "                vect_new = np.vstack((vect_new, vect.reshape(-1, 1)))\n",
    "            self.action_matrix[:, i] = vect_new.ravel()\n",
    "        self.e_sqrt_16 = np.exp(1/16)\n",
    "        self.reset()\n",
    "\n",
    "    def update(self, observations):\n",
    "        self.t += 1\n",
    "        # print(f\"t {self.t}: {observations}\")\n",
    "        for i in range(self.d):\n",
    "            self.observations[i, self.last_pull[i], self.n_pulls[i, self.last_pull[i]]] = observations[i]\n",
    "            self.n_pulls[i, self.last_pull[i]] = self.n_pulls[i, self.last_pull[i]] + 1\n",
    "\n",
    "    def threshold_lookup(self, n):\n",
    "        return np.sqrt(self.u * n / (-2 * np.log(self.t)))\n",
    "    \n",
    "    def pull_arm(self):\n",
    "        if self.bounded:\n",
    "            for i in range(self.num_actions):\n",
    "                action_vector = self.action_matrix[i, :]\n",
    "                new_min_pull = self.n_pulls[0, action_vector[0]]\n",
    "                for j in range(1, self.d):\n",
    "                    new_min_pull = min(new_min_pull, self.n_pulls[j, action_vector[j]])\n",
    "                if new_min_pull != self.n_min_pull[i]:\n",
    "                    self.n_min_pull[i] = new_min_pull\n",
    "                    aux = 1\n",
    "                    for j in range(self.d):\n",
    "                        aux *= self.observations[j, self.last_pull[j], self.n_min_pull[i]-1]\n",
    "                    self.virtual_pulls_sum[i] += aux\n",
    "            mean = self.virtual_pulls_sum / self.n_min_pull\n",
    "            ucb = mean + self.v * np.sqrt(4 * math.log(self.t) / self.n_min_pull)\n",
    "        else:\n",
    "        \n",
    "            for i in range(self.num_actions):\n",
    "                \n",
    "                action_vector = self.action_matrix[i, :]\n",
    "                if (action_vector == self.last_pull).any():\n",
    "                    new_min_pull = self.n_pulls[0, action_vector[0]]\n",
    "                    for j in range(1, self.d):\n",
    "                        new_min_pull = min(new_min_pull, self.n_pulls[j, action_vector[j]])\n",
    "                    self.n_min_pull[i] = new_min_pull\n",
    "\n",
    "                _observations = np.zeros((self.d, self.n_min_pull[i]))\n",
    "\n",
    "                for h in range(self.d):\n",
    "                    _observations[h, :] = self.observations[h, action_vector[h], :self.n_min_pull[i]]\n",
    "\n",
    "                x = np.prod(_observations, axis=0)\n",
    "                \n",
    "                # Truncated Mean\n",
    "                # self.virtual_pulls_sum[i] = np.mean(np.where(np.abs(x) <= self.threshold_lookup(self.t), x, 0))\n",
    "                # Median of Means\n",
    "                k = max(int(min(2+32*np.log(self.t), self.n_min_pull[i])/2), 1)\n",
    "                N = int(self.n_min_pull[i]/k)\n",
    "                self.virtual_pulls_sum[i] = np.median([np.mean(chunk) for chunk in np.array_split(x[:N*k], k)])\n",
    "\n",
    "            mean = self.virtual_pulls_sum\n",
    "            \n",
    "            # Truncated Mean\n",
    "            # ucb = mean + self.v * np.sqrt(np.sqrt(2)*2*np.log(self.t)/self.n_min_pull)\n",
    "            # Median of Means\n",
    "            ucb = mean + np.sqrt(12 * self.v * 32 * np.log(self.e_sqrt_16 * self.t) / self.n_min_pull)\n",
    "            ucb = np.nan_to_num(ucb, nan=np.inf)\n",
    "        \n",
    "        self.last_pull = self.action_matrix[np.random.choice(np.where(ucb == ucb.max())[0]), :]\n",
    "\n",
    "        return self.last_pull\n",
    "                       \n",
    "    def reset(self):\n",
    "        self.t = 1\n",
    "        self.last_pull = None\n",
    "        self.n_min_pull = np.zeros(self.num_actions, dtype=int)\n",
    "        self.n_pulls = np.zeros((self.d, self.k), dtype=int)\n",
    "        self.observations = -1 * np.ones((self.d, self.k, self.T))#, dtype=int)\n",
    "        self.virtual_pulls_sum = np.zeros(self.num_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fe5c05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BASIC SETTING FOR EXPERIMENTS\n",
    "fucb = '\\\\JPAalgnameshort'\n",
    "fucbMM = '\\\\JPAalgnameshortMM'\n",
    "ucbone = '\\\\ucbone'\n",
    "httem = '\\\\httem'\n",
    "tea = '\\\\tea'\n",
    "algs = [fucb, ucbone, httem, tea]\n",
    "T = 10000\n",
    "checkpoints = [1000, 5000, 10000]\n",
    "n_trials = 50\n",
    "seed = 0\n",
    "k_list = [3, 5]\n",
    "d_list = [1, 2, 3, 4]\n",
    "bounded_list = [False]   \n",
    "do_subsampling = True\n",
    "\n",
    "# OVERRIDE FOR TESTING PURPOSE TO SPEED UP THE RUNS\n",
    "T = 10000\n",
    "checkpoints = [1000, 2000, 5000]\n",
    "bounded_list = [False] \n",
    "algs = [fucb, tea]\n",
    "n_trials = 4\n",
    "k_list = [3]\n",
    "d_list = [1, 2]\n",
    "do_subsampling = False\n",
    "    \n",
    "result_table = {}\n",
    "\n",
    "for bounded in bounded_list:\n",
    "\n",
    "    result_table[bounded] = {}\n",
    "    \n",
    "    if bounded: \n",
    "        sigma = 0.5 # fixed for bernoulli\n",
    "    else:\n",
    "        sigma = 0.1\n",
    "    \n",
    "    for d in d_list:\n",
    "\n",
    "        result_table[bounded][d] = {}\n",
    "\n",
    "        for k in k_list:\n",
    "\n",
    "            result_table[bounded][d][k] = {}\n",
    "\n",
    "            arms_vect = k * np.ones(d, dtype=int)\n",
    "\n",
    "            # F-UCB INIT\n",
    "            agent_factored = FactoredUCBAgent(arms_vect, d, sigma)\n",
    "\n",
    "            # F-UCB-MM INIT\n",
    "            # agent_factored_MM = FactoredUCBAgentMM(k, d, T, sigma=sigma, bounded=bounded)\n",
    "            agent_factored_MM = NewFactoredUCBAgentMM(k, d, T, bounded, sigma)\n",
    "            \n",
    "            # UCB1 INIT\n",
    "            agent_ucb = UCB1Agent(d*k, sigma)\n",
    "            action_mx = create_action_matrix(d, k)\n",
    "\n",
    "            # HT-TEM INIT\n",
    "            agent_ht_tem = TMRobustUCBAgent(n_arms=d*k, u=(1+sigma**2)**d-1)\n",
    "\n",
    "            # TEA INIT\n",
    "            agent_tea = TEA(k, d)\n",
    "            \n",
    "            mean_cum_expected_regret = {}\n",
    "            std_cum_expected_regret = {}\n",
    "            \n",
    "            for alg in algs:\n",
    "\n",
    "                result_table[bounded][d][k][alg] = {}\n",
    "\n",
    "                env = FactoredEnv(arms_vect, d, sigma=sigma, bounded=bounded)\n",
    "\n",
    "                inst_expected_regret = np.zeros((n_trials, T))\n",
    "                \n",
    "                # for trial_i in range(n_trials):\n",
    "                for trial_i in tqdm(range(n_trials)):\n",
    "                \n",
    "                    vals_expected = env.get_expected()\n",
    "                    max_expected = compute_max_expected(vals_expected)\n",
    "\n",
    "                    for t in range(T):\n",
    "\n",
    "                        if alg == ucbone:\n",
    "                            action = action_mx[agent_ucb.pull_arm(), :]\n",
    "                            agent_ucb.update(np.prod(env.step(action)))\n",
    "                        elif alg == fucb:\n",
    "                            action = agent_factored.pull_arm()\n",
    "                            agent_factored.update(env.step(action))\n",
    "                        elif alg == fucbMM:\n",
    "                            action = agent_factored_MM.pull_arm()\n",
    "                            agent_factored_MM.update(env.step(action))\n",
    "                        elif alg == httem:\n",
    "                            action = action_mx[agent_ht_tem.pull_arm(), :]\n",
    "                            agent_ht_tem.update(np.prod(env.step(action)))\n",
    "                        elif alg == tea:\n",
    "                            action = agent_tea.pull_arm()\n",
    "                            agent_tea.update(np.prod(env.step(action)))\n",
    "                        else:\n",
    "                            raise ValueError('Error in selecting algorithm')\n",
    "\n",
    "                        inst_expected_regret[trial_i, t] = max_expected - get_pulled_expected(\n",
    "                            vals_expected, action)\n",
    "                    \n",
    "                    # I reset all the agents, becuase i do not know which one \n",
    "                    # i am using for the sake of simplicity\n",
    "                    \n",
    "                    if trial_i < n_trials - 1:\n",
    "                        env.reset()\n",
    "                        agent_ucb.reset()\n",
    "                    agent_factored.reset()\n",
    "                    agent_factored_MM.reset()\n",
    "                    agent_ht_tem.reset()\n",
    "                    agent_tea.reset()\n",
    "                \n",
    "                # maybe replace with cumsum with correct axis\n",
    "                cum_expected_regret = np.zeros(inst_expected_regret.shape)\n",
    "                cum_expected_regret[:, 0] = inst_expected_regret[:, 0]\n",
    "                for i in range(1, T):\n",
    "                    cum_expected_regret[:, i] = inst_expected_regret[:, i] + cum_expected_regret[:, i-1]\n",
    "\n",
    "                mean_cum_expected_regret[alg] = np.mean(cum_expected_regret, axis=0)\n",
    "                std_cum_expected_regret[alg] = np.std(cum_expected_regret, axis=0) / np.sqrt(n_trials)\n",
    "\n",
    "                print('{} run completed - k={} d={} $\\sigma$={}'.format(alg, k, d, sigma))\n",
    "                for i in checkpoints:\n",
    "                    result_table[bounded][d][k][alg][i] = '${} \\ ({})$   '.format(\n",
    "                        round(mean_cum_expected_regret[alg][i-1], 2), \n",
    "                        round(std_cum_expected_regret[alg][i-1], 2)\n",
    "                    )\n",
    "                    print('T={}: ${} \\ ({})$'.format(i, round(mean_cum_expected_regret[alg][i-1], 2), \n",
    "                                                  round(std_cum_expected_regret[alg][i-1], 2)))\n",
    "\n",
    "            plt.figure()\n",
    "            if do_subsampling:\n",
    "                subsample = 50\n",
    "                assert T % subsample == 0\n",
    "                x_plt = np.linspace(0, T-1, int(T/subsample), dtype=int)\n",
    "            else:\n",
    "                x_plt = np.linspace(0, T-1, T, dtype=int)\n",
    "            for alg in algs:\n",
    "                plt.plot(x_plt, mean_cum_expected_regret[alg][x_plt], \n",
    "                         label=alg)\n",
    "                plt.fill_between(x_plt, \n",
    "                                 mean_cum_expected_regret[alg][x_plt] - std_cum_expected_regret[alg][x_plt], \n",
    "                                 mean_cum_expected_regret[alg][x_plt] + std_cum_expected_regret[alg][x_plt], \n",
    "                                 alpha=0.3)\n",
    "            plt.legend()\n",
    "            plt.xlabel('Rounds')\n",
    "            plt.ylabel('Regret')\n",
    "            plt.title('bounded={} k={} d={} $\\sigma$={}'.format(bounded, k, d, sigma))\n",
    "            if bounded:\n",
    "                save_str = 'results/bounded_k{}_d{}'.format(k, d)\n",
    "            else:\n",
    "                save_str = 'results/subgauss_k{}_d{}'.format(k, d)\n",
    "            plt.savefig(save_str + '.png')\n",
    "            tkz.save(save_str + '.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc7c88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('d= \\t k= \\t T=\\t\\t', end='')\n",
    "[print(alg, end='\\t\\t\\t') for alg in algs]\n",
    "print('')\n",
    "\n",
    "for d in d_list:\n",
    "    for k in k_list:\n",
    "        for T_val in checkpoints:\n",
    "            print('${}$ & \\t ${}$ & \\t ${}$ \\t\\t'.format(d, k, T_val), end='')\n",
    "            for bounded in bounded_list:\n",
    "                for alg in algs:\n",
    "                    print('&', result_table[bounded][d][k][alg][T_val], end='\\t')\n",
    "            if T_val == checkpoints[-1]:\n",
    "                print('\\\\\\\\\\n\\\\cmidrule{2-10}')\n",
    "            else:\n",
    "                print('\\\\\\\\\\n\\\\cmidrule{3-10}')\n",
    "    print('\\cmidrule{1-10}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
